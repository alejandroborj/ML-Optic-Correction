[DEFAULT]
append_jobs = False
check_files = 
dryrun = False
executable = "/afs/cern.ch/user/a/aborjess/work/public/miniconda3/bin/python"
htc_arguments = {}
job_output_dir = "/afs/cern.ch/user/a/aborjess/work/public/ML-Optic-Correction/src/non_linear_tests/supervised_learning/htcondor_dataset"
jobflavour = "workday"
jobid_mask = "create_only_triplet_%%(INSTANCE)d"
mask = "exec_create_dataset.py"
num_processes = 4
replace_dict = {'INSTANCE': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}
resume_jobs = False
run_local = False
script_arguments = {}
script_extension = 
ssh = 
working_directory = "/afs/cern.ch/user/a/aborjess/work/public/ML-Optic-Correction/src/non_linear_tests/supervised_learning/HTCondor_submit"
