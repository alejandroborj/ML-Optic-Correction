executable = /afs/cern.ch/user/a/aborjess/work/public/miniconda3/bin/python
arguments = create_dataset.py

run_local = True
initialdir = /afs/cern.ch/user/a/aborjess/work/public/ML-Optic-Correction/src/non_linear_tests/supervised_learning
#Running locally or in htcondor

#executable            = generate_dataset.sh
#arguments             = $(ClusterId) $(ProcId)
output                = output/generate_dataset.$(ClusterId).$(ProcId).out
error                 = output/generate_dataset.$(ClusterId).$(ProcId).err
log                   = output/generate_dataset.$(ClusterId).log

#dryrun = True

#should_transfer_files = YES
#when_to_transfer_output = ON_EXIT

# request_cpus = 10
# Amount of parallelized cores max 18
# transfer_output_files = ./htcondor_dataset/samples, ./htcondor_dataset_dataset/errors


# +MaxRuntime = 50


queue 1